# Introduction des paramètres après les tests faits dans le notebook

# Paramètres de split des données
data_ingestion:
  test_size: 0.20

preprocess:
  text_col: "text"
  out_col: "text_norm"
  min_words: 3


# features ingenering
feature_engineering:
  text_col: "text_norm"
  label_col: "label"
  methods: ["bow", "tfidf"]     # ou ["tfidf"] seulement
  min_df: 5 # Un mot doit apparaître dans au moins 5 documents pour être gardé
  max_df: 0.9 # Un mot qui apparaît dans plus de 90 % des documents est supprimé
  token_pattern: "\\b[a-z]{3,15}\\b" # Un token valide doit respecter exactement ce pattern regex
  ngram_range: [1, 2]
  sublinear_tf: true
  norm: "l2"



# Paramètres du modèle
model_building:
  features_type: "bow"
  random_state: 42

xgboost:
  learning_rate: 0.2
  n_estimators: 800
  reg_alpha: 0.1
  reg_lambda: 0.5
  n_jobs: -1

lightgbm:
  learning_rate: 0.2
  n_estimators: 800
  reg_alpha: 0.1
  reg_lambda: 0.5
  n_jobs: -1

# Partie MLflow

mlflow:
  tracking_uri: "sqlite:///mlflow.db"         # Où MLflow va stocker les runs, métriques, paramètres et artefacts (recommandé pour Model Registry)
  experiment_name: "sentiment-model-evaluation"
  registry_model_name: "sentiment-classifier"  # nom dans le registry

register_model:
  metric_key: "auc_ovr_macro"                  # critère de sélection